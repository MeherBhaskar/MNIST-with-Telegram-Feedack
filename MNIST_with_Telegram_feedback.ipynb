{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST with Telegram feedback",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/zVyKcxZE3AhWQ0UxvcB6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeherBhaskar/MNIST-with-Telegram-Feedack/blob/master/MNIST_with_Telegram_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ82BkcgKUWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c67ac14b-d669-43ad-a0b6-af8df373faef"
      },
      "source": [
        "import time\n",
        "import requests\n",
        "import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNU35Gl4Mj8P",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCe3pPrVMKdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "access_token = '1347289675:AAF2OqATE8Hw7RNyMKXXyk1bxge-GxlGvqQ'\n",
        "\n",
        "class botCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self,access_token):\n",
        "        self.access_token = access_token\n",
        "        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/getUpdates'\n",
        "        self.response = requests.get(self.ping_url).json()\n",
        "        self.chat_id = self.response['result'][0]['message']['chat']['id']\n",
        "        self.send_message('Initiating Model Monitoring')\n",
        "\n",
        "    def send_message(self,message):\n",
        "        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/sendMessage?'+\\\n",
        "                        'chat_id='+str(self.chat_id)+\\\n",
        "                        '&parse_mode=Markdown'+\\\n",
        "                        '&text='+message\n",
        "        self.response = requests.get(self.ping_url)\n",
        "    \n",
        "    def send_photo(self,filepath):\n",
        "        file_ = open(filepath,'rb')\n",
        "        file_dict = {'photo':file_}\n",
        "        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/sendPhoto?'+\\\n",
        "                    'chat_id='+str(self.chat_id)\n",
        "        self.response = requests.post(self.ping_url,files = file_dict)\n",
        "        file_.close()\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        message = 'Training started'\n",
        "        self.send_message(message)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        message = 'Model Training Completed'\n",
        "        self.send_message(message)\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        ##print(logs.keys())\n",
        "        pass\n",
        "        \n",
        "    \n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        # # print(logs.keys())  \n",
        "        # message = '~~~Training Log for Batch {}~~~\\n'.format(batch)\n",
        "        # message += 'Training Accuracy : {:7.2f}%\\n Training Loss : {:7.2f}\\n'.format(logs['accuracy']*100,logs['loss'])\n",
        "        # #message += ' Validation Loss : {:7.2f}\\n'.format(logs['val_loss'])\n",
        "        # self.send_message(message)\n",
        "        pass\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        ##print(logs.keys())  \n",
        "        \n",
        "        pass\n",
        "    \n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        # print(logs.keys())   \n",
        "        # message = '~~~Test Log for Batch {}~~~\\n'.format(batch_size)\n",
        "        # message += 'Test Accuracy : {:7.2f}%\\n Test Loss : {:7.2f}\\n'.format(logs['accuracy']*100,logs['loss'])\n",
        "        \n",
        "        # #message += ' Validation Loss : {:7.2f}\\n'.format(logs['val_loss'])\n",
        "        # self.send_message(message)\n",
        "        pass\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        pass\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(logs.keys()) \n",
        "        message = '~~~Epoch {} Log~~~\\n'.format(epoch)\n",
        "        \n",
        "        message += ' Training Accuracy : {:7.2f}%\\n Training Loss : {:7.2f}\\n'.format(logs['accuracy']*100,logs['loss'])\n",
        "        message += ' Validation Loss : {:7.2f}\\n Validation Accuracy : {:7.2f}%'.format(logs['val_loss'],logs['val_accuracy']*100)\n",
        "        self.send_message(message)\n",
        "        pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFgSqmwyZ4HL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9pWGY_FNSEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot_callback = botCallback(access_token)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jub68-jNise",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2sbashEOpex",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "365ca310-eea3-4752-fb9b-111c213aba4d"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT4h6wSaOx7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18a3bf06-8339-409e-b651-b09b3de86a2c"
      },
      "source": [
        "print(x_train.shape)\n",
        "print('Shape after formating', x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
        "x_train = x_train.astype(np.float32)\n",
        "x_test = x_test.astype(np.float32)\n",
        "\n",
        "\n",
        "img_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "x_train/=255\n",
        "x_test/=255"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Shape after formating (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldfzJ7BCO0El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "num_pixels = x_train.shape[1]*x_train.shape[2]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n81Zkj0KO6Iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bd6a8add-6eec-47d0-b4d0-7141fb918550"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "## Build the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = img_shape))\n",
        "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation = 'softmax'))\n",
        "# compile model\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1rT4s7SO8Xw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ba7bcd05-92d0-4305-b0b0-da2bcfea6691"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 1000\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('/content/sample_data/temp_modek', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, \n",
        "                                   verbose=1, mode='min', min_lr=0.00001)\n",
        "                              \n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = (x_test, y_test),\n",
        "                    callbacks = [ reduce_lr, early_stop, bot_callback])\n",
        "score = model.evaluate(x_test, y_test, verbose = 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1000\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n",
            "Epoch 2/1000\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0273 - val_accuracy: 0.9916\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n",
            "Epoch 3/1000\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9913\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n",
            "Epoch 4/1000\n",
            "60000/60000 [==============================] - 5s 89us/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.0275 - val_accuracy: 0.9918\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy', 'lr'])\n",
            "10000/10000 [==============================] - 1s 114us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GTCB8HyPVlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}